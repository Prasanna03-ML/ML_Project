{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yX67LClQdHQ3"
      },
      "outputs": [],
      "source": [
        "# Import the libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OrdinalEncoder\n",
        "from sklearn.linear_model import LinearRegression,Lasso,Ridge\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score , make_scorer , mean_squared_log_error\n",
        "from sklearn.ensemble import  RandomForestRegressor , GradientBoostingRegressor , VotingRegressor , StackingRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from statsmodels.tools.tools import add_constant\n",
        "\n",
        "# Remove Warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zog1dc-KiIqQ"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/data.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/content/data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\prasa\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
            "File \u001b[1;32mc:\\Users\\prasa\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
            "File \u001b[1;32mc:\\Users\\prasa\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
            "File \u001b[1;32mc:\\Users\\prasa\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
            "File \u001b[1;32mc:\\Users\\prasa\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/data.csv'"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(\"/content/data.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "vkQvDxfTiU58",
        "outputId": "069f0bb6-41d9-4bf3-dc79-dea95a6cf72b"
      },
      "outputs": [],
      "source": [
        "pd.set_option('display.max_rows', None)  # Show all rows\n",
        "pd.set_option('display.max_columns', None)  # Show all columns\n",
        "pd.set_option('display.width', None)  # No limit on display width\n",
        "df.head(10)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "yRUKRuJtic6m",
        "outputId": "d061ae0d-4300-4aae-c9a3-7d12fc9efc74"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FDg-bn2i9VQ",
        "outputId": "cd79cb79-f068-4cce-c888-c0c6eef268cb"
      },
      "outputs": [],
      "source": [
        "#splitting the data into numerical and categorical\n",
        "numerical = df.select_dtypes(include = ['float64', 'int64']).columns.tolist()\n",
        "categorical = df.select_dtypes(include = ['object']).columns.tolist()\n",
        "\n",
        "print('number of numerical features is: ' , len(numerical))\n",
        "print('number of categorical features is: ' , len(categorical))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "wYoz41d2jRvn",
        "outputId": "260cc7b8-3187-4245-971b-ec8219f25173"
      },
      "outputs": [],
      "source": [
        "df[numerical].describe().T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "gWddIhGsjUlN",
        "outputId": "a9219043-6d01-460b-c2fc-349c37dc39be"
      },
      "outputs": [],
      "source": [
        "df[categorical].describe().T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "Eop7MDPujdpd",
        "outputId": "8f73c44a-34b7-4765-a5a8-59c680ac224a"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(13, 3, figsize=(20, 5 * 13))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, feature in enumerate(df[numerical]):\n",
        "    sns.scatterplot(ax=axes[i], x=df[feature], y=df['SalePrice'])\n",
        "    axes[i].set_title(f'SalePrice vs {feature}')\n",
        "    axes[i].set_xlabel(feature)\n",
        "    axes[i].set_ylabel('SalePrice')\n",
        "\n",
        "for j in range(i + 1, len(axes)):\n",
        "    fig.delaxes(axes[j])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ynx-cwwYkLB1"
      },
      "outputs": [],
      "source": [
        "#outlier detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "id": "RSFgQhEokNWF",
        "outputId": "55a7da63-1930-46cf-8445-e0cbf5624e40"
      },
      "outputs": [],
      "source": [
        "# Identifying two data points with the highest SalePrice.\n",
        "df.sort_values(by = 'SalePrice', ascending = False)[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "id": "eekd7N_ikcE1",
        "outputId": "61ea49d0-e71d-4384-d712-0b116ad71c48"
      },
      "outputs": [],
      "source": [
        "# Identifying two data points with the lowest SalePrice.\n",
        "df.sort_values(by = 'SalePrice', ascending = True)[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Oak2Kwuk-ml"
      },
      "outputs": [],
      "source": [
        "# Removing the data points that we identified above. We will remove them using the values from the Id column.\n",
        "\n",
        "df = df.drop(df[df['Id'] == 692].index)\n",
        "df = df.drop(df[df['Id'] == 1183].index)\n",
        "df = df.drop(df[df['Id'] == 1537].index)\n",
        "df = df.drop(df[df['Id'] == 2217].index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "2Qf4qazeljl-",
        "outputId": "0ab1c470-b829-435e-bde7-785327b5ea32"
      },
      "outputs": [],
      "source": [
        "var = 'GrLivArea'\n",
        "data = pd.concat([df['SalePrice'] , df[var]] , axis =1)\n",
        "data.plot.scatter(x = var , y ='SalePrice', ylim = (0,800000));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "z8ytSNZ1loAd",
        "outputId": "b75c40c9-e4e3-4fef-cf8b-74d053c8a38d"
      },
      "outputs": [],
      "source": [
        "# Identifying points\n",
        "df.sort_values(by = 'GrLivArea', ascending = False)[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6jcjfwzplxyu"
      },
      "outputs": [],
      "source": [
        "# Removing the data points that we identified above. We will remove them using the values from the Id column.\n",
        "\n",
        "df = df.drop(df[df['Id'] == 1299].index)\n",
        "df = df.drop(df[df['Id'] == 1170].index)\n",
        "df = df.drop(df[df['Id'] == 524].index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "ttYHx7J_l2hO",
        "outputId": "b167e130-fd4c-41a5-b879-c2466269fd0f"
      },
      "outputs": [],
      "source": [
        "var = 'LotFrontage'\n",
        "data = pd.concat([df['SalePrice'] , df[var]] , axis =1)\n",
        "data.plot.scatter(x = var , y ='SalePrice', ylim = (0,800000));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "id": "6DXx6ibUl5t1",
        "outputId": "ec9526b2-fde9-4daf-e507-421d02b6b61d"
      },
      "outputs": [],
      "source": [
        "# Identifying points\n",
        "df.sort_values(by = 'LotFrontage', ascending = False)[:1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5OA1mtKul8Ux"
      },
      "outputs": [],
      "source": [
        "# deleting points\n",
        "df = df.drop(df[df['Id'] == 935].index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "IrS_83msmKqO",
        "outputId": "422b1888-e419-4771-96f5-de51b4bf2478"
      },
      "outputs": [],
      "source": [
        "var = 'MasVnrArea'\n",
        "data = pd.concat([df['SalePrice'] , df[var]] , axis =1)\n",
        "data.plot.scatter(x = var , y ='SalePrice', ylim = (0,800000));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "id": "VYQNTDPlmQ0d",
        "outputId": "c3bd9181-4b19-4008-b175-378b1445f5ae"
      },
      "outputs": [],
      "source": [
        "# Identifying points\n",
        "df.sort_values(by = 'MasVnrArea', ascending = False)[:1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xzP-19omUoO"
      },
      "outputs": [],
      "source": [
        "# deleting points\n",
        "df = df.drop(df[df['Id'] == 298].index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "1VzdFVT1mbV2",
        "outputId": "36d20188-4b57-4def-e2c8-66b6f218f25a"
      },
      "outputs": [],
      "source": [
        "var = 'BsmtFinSF1'\n",
        "data = pd.concat([df['SalePrice'] , df[var]] , axis =1)\n",
        "data.plot.scatter(x = var , y ='SalePrice', ylim = (0,800000));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "vtETS3b9mi-v",
        "outputId": "0c9f2ea5-3ec7-4e13-b5ee-5b3a5d1917dd"
      },
      "outputs": [],
      "source": [
        "var = 'TotalBsmtSF'\n",
        "data = pd.concat([df['SalePrice'] , df[var]] , axis =1)\n",
        "data.plot.scatter(x = var , y ='SalePrice', ylim = (0,800000));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "PkVTsuF0mseW",
        "outputId": "94085285-4c81-49ca-e4b3-287f65ea4ade"
      },
      "outputs": [],
      "source": [
        "var = '1stFlrSF'\n",
        "data = pd.concat([df['SalePrice'] , df[var]] , axis =1)\n",
        "data.plot.scatter(x = var , y ='SalePrice', ylim = (0,800000));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "PhrRpUjVnb7y",
        "outputId": "b2decc48-a7bd-4a0b-a4bc-56d3c1e82376"
      },
      "outputs": [],
      "source": [
        "var = 'GarageArea'\n",
        "data = pd.concat([df['SalePrice'] , df[var]] , axis =1)\n",
        "data.plot.scatter(x = var , y ='SalePrice', ylim = (0,800000));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "bWkKnzesniY-",
        "outputId": "08f7a8a7-f9e2-4749-de6d-9e1c6e7faa61"
      },
      "outputs": [],
      "source": [
        "var = 'OpenPorchSF'\n",
        "data = pd.concat([df['SalePrice'] , df[var]] , axis =1)\n",
        "data.plot.scatter(x = var , y ='SalePrice', ylim = (0,800000));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "BHe9Mz9LnloW",
        "outputId": "00588814-2d06-4a1b-a4a5-c64fed188b35"
      },
      "outputs": [],
      "source": [
        "# Identifying points\n",
        "df.sort_values(by = 'OpenPorchSF', ascending = False)[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ObBZNpw9noMH"
      },
      "outputs": [],
      "source": [
        "# deleting points\n",
        "\n",
        "df = df.drop(df[df['Id'] == 496].index)\n",
        "df = df.drop(df[df['Id'] == 584].index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "NafJg2vpoCg-",
        "outputId": "cdb7ba66-2dae-48a8-f8a5-38d32c09ac7f"
      },
      "outputs": [],
      "source": [
        "var = 'LotArea'\n",
        "data = pd.concat([df['SalePrice'] , df[var]] , axis =1)\n",
        "data.plot.scatter(x = var , y ='SalePrice', ylim = (0,800000));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "0CvK-d0voFCX",
        "outputId": "362e44fb-ac2e-4dbc-c05a-509a1ec7ac06"
      },
      "outputs": [],
      "source": [
        "# Identifying points\n",
        "df.sort_values(by = 'LotArea', ascending = False)[:4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SMYIw3mDoIMO"
      },
      "outputs": [],
      "source": [
        "# deleting points\n",
        "df = df.drop(df[df['Id'] == 314].index)\n",
        "df = df.drop(df[df['Id'] == 336].index)\n",
        "df = df.drop(df[df['Id'] == 250].index)\n",
        "df = df.drop(df[df['Id'] == 707].index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "YNr2DGiXoMth",
        "outputId": "9069c1cc-a781-4bdd-a1c2-37177b7fa305"
      },
      "outputs": [],
      "source": [
        "var = 'GarageYrBlt'\n",
        "data = pd.concat([df['SalePrice'] , df[var]] , axis =1)\n",
        "data.plot.scatter(x = var , y ='SalePrice', ylim = (0,800000));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "Nfiuu8CVoUFH",
        "outputId": "bce0481e-ea94-4fb6-958e-b70350cb4f31"
      },
      "outputs": [],
      "source": [
        "var = 'WoodDeckSF'\n",
        "data = pd.concat([df['SalePrice'] , df[var]] , axis =1)\n",
        "data.plot.scatter(x = var , y ='SalePrice', ylim = (0,800000));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "KwoPDHDkogKW",
        "outputId": "91c24f5e-91b1-4959-ed07-d5188fb91685"
      },
      "outputs": [],
      "source": [
        "var = 'EnclosedPorch'\n",
        "data = pd.concat([df['SalePrice'] , df[var]] , axis =1)\n",
        "data.plot.scatter(x = var , y ='SalePrice', ylim = (0,800000));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRGcuiLNotEe"
      },
      "outputs": [],
      "source": [
        "# filling missing values, feature engineering and encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCP0QJShoyDO",
        "outputId": "067e1cca-ce3d-489a-962d-cc3535ef4835"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "YMvI4LaYo0Lk",
        "outputId": "9aecf584-b493-44e3-ebf7-801d7cba476c"
      },
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "collapsed": true,
        "id": "hXekWxeUpF1W",
        "outputId": "17c89479-e9c3-43c4-bbe1-77b62a0511c6"
      },
      "outputs": [],
      "source": [
        "# Calculate the ratio of missing data\n",
        "null_data_ratio = (df.isnull().sum()) * 100 / df.shape[0]\n",
        "null_data_ratio = null_data_ratio.drop(null_data_ratio[null_data_ratio == 0].index).sort_values(ascending=False)\n",
        "null_data_ratio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "78TymDDdr78A",
        "outputId": "724595bc-4483-4cd3-9b5e-779357248738"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "for column in df.select_dtypes(include=np.number).columns:\n",
        "    plt.figure() # create a new figure for each plot\n",
        "    df.boxplot(column=column)\n",
        "    plt.title(f'Box plot of {column}')\n",
        "    plt.ylabel('Value')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ZiuOC24sfnw"
      },
      "outputs": [],
      "source": [
        "def Missing_values(df):\n",
        "    df['MasVnrType'].fillna(df['MasVnrType'].mode()[0] , inplace = True)\n",
        "    df['MasVnrArea'].fillna(df['MasVnrArea'].mean(), inplace = True)\n",
        "\n",
        "\n",
        "    NA_features = ['PoolQC','BsmtQual', 'BsmtCond', 'BsmtExposure', 'FireplaceQu', 'GarageFinish',\n",
        "                 'GarageQual', 'GarageCond', 'GarageType' , 'Fence', 'Alley', 'BsmtFinType1', 'BsmtFinType2',\n",
        "                 'MiscFeature']\n",
        "    for i in NA_features:\n",
        "        df[i].fillna('No' , inplace = True)\n",
        "\n",
        "    # Zero imputing missing values:\n",
        "    missing_features_1 = ['BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF',\n",
        "                          'BsmtFullBath', 'BsmtHalfBath','GarageArea', 'GarageCars']\n",
        "    for col in missing_features_1:\n",
        "        df[col] = df[col].fillna(0)\n",
        "\n",
        "    # imputing with mode:\n",
        "    missing_features_2 = ['MSZoning', 'Electrical', 'KitchenQual', 'Exterior1st', 'Exterior2nd',\n",
        "                         'SaleType', 'Utilities']\n",
        "    for col in missing_features_2:\n",
        "        df[col] = df[col].fillna(df[col].mode()[0])\n",
        "\n",
        "    # Regarding the LotFrontage feature, the best approach is to use the mode values to fill in the missing data for different categories of the Neighborhood.\n",
        "    # LotFrontage:\n",
        "    df[\"LotFrontage\"] = df.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(\n",
        "       lambda x: x.fillna(x.median()))\n",
        "\n",
        "    # Functional :\n",
        "    df['Functional'] = df['Functional'].fillna('Typ')\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0XkSaUZs-Vx"
      },
      "outputs": [],
      "source": [
        "def Feature_engineering(df):\n",
        "    df['Age_of_property'] = (df['YrSold'] - df['YearBuilt']) *12 + df['MoSold']\n",
        "    df['Age_of_remodel'] = (df['YrSold'] - df['YearRemodAdd']) * 12 + df['MoSold']\n",
        "    df['Age_of_garage'] = (df['YrSold'] - df['GarageYrBlt']) * 12 + df['MoSold']\n",
        "    df['Age_of_garage'].fillna(0 , inplace = True)\n",
        "    df['TotalSF'] = df['TotalBsmtSF'] + df['1stFlrSF'] + df['2ndFlrSF']\n",
        "    df['TotalBathrooms'] = (df['FullBath'] + (0.5 * df['HalfBath']) +\n",
        "                             df['BsmtFullBath'] + (0.5 * df['BsmtHalfBath']))\n",
        "    df['TotalPorchSF'] = df['WoodDeckSF'] + df['OpenPorchSF'] + df['EnclosedPorch'] + df['3SsnPorch'] + df['ScreenPorch']\n",
        "\n",
        "    items_to_drop = ['YrSold' , 'YearBuilt' , 'MoSold' ,  'YearRemodAdd' , 'GarageYrBlt' ,  'TotalBsmtSF'\n",
        "                   , '1stFlrSF' , '2ndFlrSF' ,  'FullBath' , 'HalfBath' , 'BsmtFullBath' , 'BsmtHalfBath' , 'WoodDeckSF' , 'OpenPorchSF'\n",
        "                     , 'EnclosedPorch' , '3SsnPorch' , 'ScreenPorch']\n",
        "    df.drop(items_to_drop , axis = 1 , inplace =True)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TL7SClEetDLI"
      },
      "outputs": [],
      "source": [
        "def cat_to_num(df):\n",
        "\n",
        "    ordinal_features = ['LotShape' , 'LandContour' , 'LandSlope' , 'ExterQual' , 'ExterCond' , 'BsmtQual', 'BsmtCond' , 'BsmtExposure', 'BsmtFinType1' , 'BsmtFinType2' , 'HeatingQC',\n",
        "                        'Electrical' , 'KitchenQual' , 'FireplaceQu' , 'GarageFinish' , 'GarageQual' , 'GarageCond', 'PavedDrive' , 'PoolQC' , 'Fence' , 'CentralAir']\n",
        "\n",
        "    ordinal_categories = [\n",
        "            ['IR3' , 'IR2' , 'IR1' , 'Reg'] #LotShape categories\n",
        "            ,['Low' , 'HLS' , 'Bnk' , 'Lvl'] #LandContour categories\n",
        "            ,['Sev' , 'Mod' , 'Gtl'] #LandSlope categories\n",
        "            ,['Po' , 'Fa' , 'TA' , 'Gd' , 'Ex'] #ExterQual categories\n",
        "            ,['Po' , 'Fa' , 'TA' , 'Gd' , 'Ex'] #ExterCond categories\n",
        "            ,['No' , 'Po' , 'Fa' , 'TA' , 'Gd' , 'Ex'] #BsmtQual categories\n",
        "            ,['No' , 'Po' , 'Fa' , 'TA' , 'Gd' , 'Ex'] #BsmtCond categories\n",
        "            ,['No' , 'Mn' , 'Av' , 'Gd'] #BsmtExposure categories\n",
        "            ,['No' , 'Unf' , 'LwQ' , 'Rec' , 'BLQ' , 'ALQ' , 'GLQ'] #BsmtFinType1 categories\n",
        "            ,['No' , 'Unf' , 'LwQ' , 'Rec' , 'BLQ' , 'ALQ' , 'GLQ'] #BsmtFinType2 categories\n",
        "            ,['Po' , 'Fa' , 'TA' , 'Gd' , 'Ex'] #HeatingQC categories\n",
        "            ,['Mix' , 'FuseP' , 'FuseF' , 'FuseA' , 'SBrkr'] #Electrical categories\n",
        "            ,['Po' , 'Fa' , 'TA' , 'Gd' , 'Ex'] #KitchenQual categories\n",
        "            ,['No' , 'Po' , 'Fa' , 'TA' , 'Gd' , 'Ex'] #FireplaceQu categories\n",
        "            ,['No' , 'Unf' , 'RFn' , 'Fin'] #GarageFinish categories\n",
        "            ,['No' , 'Po' , 'Fa' , 'TA' , 'Gd' , 'Ex'] #GarageQual categories\n",
        "            ,['No' , 'Po' , 'Fa' , 'TA' , 'Gd' , 'Ex'] #GarageCond categories\n",
        "            ,['N' , 'P' , 'Y'] #PavedDrive categories\n",
        "            ,['No' , 'Fa' , 'TA' , 'Gd' , 'Ex'] #PoolQC categories\n",
        "            ,['No' , 'MnWw' , 'GdWo' , 'MnPrv' , 'GdPrv'] #Fence categories\n",
        "            ,['N' , 'Y'] #CentralAir categories\n",
        "            ]\n",
        "    encoder = OrdinalEncoder(categories = ordinal_categories)\n",
        "    df[ordinal_features] = encoder.fit_transform(df[ordinal_features])\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x42BGZFFtGsw"
      },
      "outputs": [],
      "source": [
        "def transformer(df):\n",
        "\n",
        "    mv = Missing_values(df)\n",
        "\n",
        "    Fe = Feature_engineering(mv)\n",
        "\n",
        "    df = cat_to_num(Fe)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2dW5Cdu-tItQ"
      },
      "outputs": [],
      "source": [
        "df = transformer(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqxW6oNFxCFJ"
      },
      "outputs": [],
      "source": [
        "df['MSSubClass'] = df['MSSubClass'].apply(str)\n",
        "nominal_features = ['MSSubClass' , 'MSZoning' , 'Street' , 'Alley' , 'Utilities' , 'LotConfig' , 'Neighborhood' , 'Condition1' , 'Condition2' , 'BldgType' , 'HouseStyle'\n",
        "                    , 'RoofStyle' , 'RoofMatl' , 'Exterior1st', 'Exterior2nd' , 'MasVnrType' , 'Foundation' , 'Heating' , 'Functional' , 'GarageType' , 'MiscFeature'\n",
        "                    ,'SaleType' ,  'SaleCondition']\n",
        "\n",
        "df = pd.get_dummies(df, columns=nominal_features, drop_first=True)\n",
        "\n",
        "\n",
        "bool_columns = df.select_dtypes(include=['bool']).columns  # انتخاب ستون‌های Boolean\n",
        "\n",
        "for col in bool_columns:\n",
        "    df[col] = df[col].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "D9w7ZYlztmF_",
        "outputId": "26f9afcf-e3b5-4f5b-aa9b-713e296d4a4a"
      },
      "outputs": [],
      "source": [
        "# feature selection\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "3W64HvXYtxZY",
        "outputId": "747227b0-786c-4a10-8477-33cf47ec589f"
      },
      "outputs": [],
      "source": [
        "corr_train=df.corr()\n",
        "low_corr_features = corr_train[(corr_train['SalePrice'] < 0.1) & (corr_train['SalePrice']> -0.1)].index\n",
        "df_filtered = df.drop(columns=low_corr_features)\n",
        "\n",
        "corr_train=df_filtered.corr()\n",
        "print(corr_train['SalePrice'].sort_values(ascending = False))\n",
        "plt.figure(figsize=(34, 30))\n",
        "\n",
        "plt.title(\"Correlation Matrix\",color=\"red\",fontsize=15)\n",
        "sns.heatmap(corr_train, annot=False, cmap='coolwarm', fmt ='.2f')\n",
        "plt.title('Correlation Heatmap')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afWRey6r03OR",
        "outputId": "64a539f8-a37e-4c90-ebfb-9d320c7b0d32"
      },
      "outputs": [],
      "source": [
        "corr_train=df_filtered.corr()\n",
        "high_corr_pairs_with_values = []\n",
        "\n",
        "# Identifying features with a correlation higher than 0.7\n",
        "threshold = 0.7\n",
        "for col in corr_train.columns:\n",
        "    for row in corr_train.index:\n",
        "        if col != row and abs(corr_train.loc[row, col]) > threshold:\n",
        "            high_corr_pairs_with_values.append((row, col, corr_train.loc[row, col]))\n",
        "\n",
        "# Displaying correlated features along with their correlation values\n",
        "for feature1, feature2, corr_value in high_corr_pairs_with_values:\n",
        "    print(f\" {feature1} - {feature2}: {corr_value:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f1uIHc7110QJ"
      },
      "outputs": [],
      "source": [
        "drop_items= ['ExterQual' , 'BsmtFinSF1' , 'GrLivArea' , 'Fireplaces' , 'GarageArea' , 'GarageCond' , 'Exterior1st_VinylSd'  , 'HouseStyle_2Story' ,\n",
        "               'Exterior1st_VinylSd' , 'GarageType_No' , 'MSZoning_RL' , 'RoofStyle_Gable' , 'Foundation_CBlock' , 'GarageType_Attchd' , 'SaleType_WD' , 'SaleCondition_Partial'\n",
        "                , 'BldgType_Duplex' , 'Exterior1st_Wd Sdng' , 'MasVnrType_BrkFace' , 'Exterior2nd_CmentBd' , 'Exterior2nd_MetalSd', 'MSSubClass_90' , 'Age_of_garage' ,\n",
        "              'MSSubClass_190' , 'MSSubClass_90']\n",
        "df_filtered.drop(drop_items , axis = 1 , inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "WZ8eC9AZ18Ly",
        "outputId": "8ce6485b-ebd0-49e4-c996-e3ad0cebcffc"
      },
      "outputs": [],
      "source": [
        "# Step 1: Add a constant (intercept) for the regression model\n",
        "X = add_constant(df_filtered)\n",
        "\n",
        "# Step 2: Create a DataFrame to store VIF values\n",
        "vif_data = pd.DataFrame()\n",
        "vif_data['Feature'] = X.columns\n",
        "\n",
        "# Step 3: Calculate VIF for each feature\n",
        "vif_data['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "\n",
        "# Display VIF values\n",
        "print(vif_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "collapsed": true,
        "id": "CU9IHRNn2sQj",
        "outputId": "9326be90-e044-4b7f-f7b2-a51c83de521c"
      },
      "outputs": [],
      "source": [
        "df_filtered.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sOpNZUr22g96"
      },
      "outputs": [],
      "source": [
        "# Separating the target from the features in order to continue the model-building process.\n",
        "target = df_filtered['SalePrice']\n",
        "features = df_filtered.drop('SalePrice' , axis =1)\n",
        "feature_names = features.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6bPvtQHJ36m0"
      },
      "outputs": [],
      "source": [
        "# Standardizing the features using the StandardScaler method.\n",
        "scaler = StandardScaler()\n",
        "scaled_features = pd.DataFrame(scaler.fit_transform(features) , columns = features.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CEzjH1fD4DS5"
      },
      "outputs": [],
      "source": [
        "# Splitting the data into training and test sets.\n",
        "x_train , x_test, y_train , y_test  = train_test_split(scaled_features , target ,test_size = 0.2, random_state = 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "oh1qlBG7uhwF",
        "outputId": "4b1c48ba-1daf-43e6-b9ff-2d55c9fa62ef"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Initialize and train the Linear Regression model\n",
        "model = LinearRegression()\n",
        "model.fit(x_train,y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "# Model evaluation\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"Mean Absolute Error (MAE):\", mae)\n",
        "print(\"Mean Squared Error (MSE):\", mse)\n",
        "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
        "print(\"R-squared (R²):\", r2)\n",
        "# Calculate R-squared\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Number of observations and predictors\n",
        "n = len(y_test)\n",
        "p = x_test.shape[1]\n",
        "\n",
        "# Adjusted R-squared formula\n",
        "adjusted_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
        "\n",
        "print(\"Adjusted R-squared:\", adjusted_r2)\n",
        "\n",
        "\n",
        "# Plotting the actual vs predicted values\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x=y_test, y=y_pred)\n",
        "plt.title(\"Actual vs Predicted Prices\")\n",
        "plt.xlabel(\"Actual Prices\")\n",
        "plt.ylabel(\"Predicted Prices\")\n",
        "plt.show()\n",
        "\n",
        "# Plot residuals\n",
        "residuals = y_test - y_pred\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(residuals, kde=True, bins=10)\n",
        "plt.title(\"Residuals Distribution\")\n",
        "plt.xlabel(\"Residuals\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErmQqPGszsdd",
        "outputId": "f3466bcf-5663-4086-862f-8a55d3af95e9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor  # For regression\n",
        "from sklearn.metrics import mean_squared_error, r2_score  # Evaluation metrics\n",
        "from sklearn.preprocessing import StandardScaler #Scaling\n",
        "\n",
        "\n",
        "#Scale the features (important for many ML algorithms)\n",
        "scaler = StandardScaler()\n",
        "x_train_scaled = scaler.fit_transform(x_train) #Fit and transform training data\n",
        "x_test_scaled = scaler.transform(x_test) #Transform test data using the fitted scaler\n",
        "\n",
        "x_train_scaled = pd.DataFrame(x_train_scaled, columns = x_train.columns)\n",
        "x_test_scaled = pd.DataFrame(x_test_scaled, columns = x_test.columns)\n",
        "\n",
        "\n",
        "#Create and train the Random Forest Regressor\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)  # Adjust hyperparameters as needed\n",
        "rf_model.fit(x_train_scaled, y_train)\n",
        "\n",
        "#Make predictions on the test set\n",
        "y_pred = rf_model.predict(x_test_scaled)\n",
        "\n",
        "#Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = mse**0.5 #Root Mean Squared Error\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"Root Mean Squared Error: {rmse}\")\n",
        "print(f\"R-squared: {r2}\")\n",
        "print(\"-----------------------------------------------------------------------\")\n",
        "\n",
        "\n",
        "#Hyperparameter Tuning using GridSearchCV or RandomizedSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=3, scoring='neg_mean_squared_error', n_jobs = -1)\n",
        "grid_search.fit(x_train_scaled, y_train)\n",
        "\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "\n",
        "y_pred_tuned = best_rf_model.predict(x_test_scaled)\n",
        "mse_tuned = mean_squared_error(y_test, y_pred_tuned)\n",
        "rmse_tuned = mse_tuned**0.5\n",
        "r2_tuned = r2_score(y_test, y_pred_tuned)\n",
        "\n",
        "print(f\"Tuned Mean Squared Error: {mse_tuned}\")\n",
        "print(f\"Tuned Root Mean Squared Error: {rmse_tuned}\")\n",
        "print(f\"Tuned R-squared: {r2_tuned}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4n_ITGoW2UeA",
        "outputId": "88212bbb-8dc3-48b2-f884-9128504cbd80"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import GradientBoostingRegressor  # For regression\n",
        "from sklearn.metrics import mean_squared_error, r2_score  # Evaluation metrics\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "\n",
        "#Scale features (important!)\n",
        "scaler = StandardScaler()\n",
        "x_train_scaled = scaler.fit_transform(x_train)\n",
        "x_test_scaled = scaler.transform(x_test)\n",
        "\n",
        "x_train_scaled = pd.DataFrame(x_train_scaled, columns = x_train.columns)\n",
        "x_test_scaled = pd.DataFrame(x_test_scaled, columns = x_test.columns)\n",
        "\n",
        "#Create and train the Gradient Boosting Regressor\n",
        "gb_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)  # Adjust hyperparameters\n",
        "gb_model.fit(x_train_scaled, y_train)\n",
        "\n",
        "#Make predictions\n",
        "y_pred = gb_model.predict(x_test_scaled)\n",
        "\n",
        "#Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = mse**0.5\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"Root Mean Squared Error: {rmse}\")\n",
        "print(f\"R-squared: {r2}\")\n",
        "print(\"-----------------------------------------------------------------------\")\n",
        "\n",
        "\n",
        "#Hyperparameter Tuning (using GridSearchCV example)\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'learning_rate': [0.01, 0.1, 0.5],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=gb_model, param_grid=param_grid, cv=3, scoring='neg_mean_squared_error', n_jobs = -1)\n",
        "grid_search.fit(x_train_scaled, y_train)\n",
        "\n",
        "best_gb_model = grid_search.best_estimator_\n",
        "\n",
        "y_pred_tuned = best_gb_model.predict(x_test_scaled)\n",
        "mse_tuned = mean_squared_error(y_test, y_pred_tuned)\n",
        "rmse_tuned = mse_tuned**0.5\n",
        "r2_tuned = r2_score(y_test, y_pred_tuned)\n",
        "\n",
        "print(f\"Tuned Mean Squared Error: {mse_tuned}\")\n",
        "print(f\"Tuned Root Mean Squared Error: {rmse_tuned}\")\n",
        "print(f\"Tuned R-squared: {r2_tuned}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
